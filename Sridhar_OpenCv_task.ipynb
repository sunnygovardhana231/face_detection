{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7bcadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytube in c:\\users\\shri\\appdata\\roaming\\python\\python311\\site-packages (15.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9e919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import cv2\n",
    "import pytube\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80bde15",
   "metadata": {},
   "source": [
    "# TASK DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181894ed",
   "metadata": {},
   "source": [
    "The task, is to take a video and split all the frames in the video and outline all the faces present in the video. \n",
    "In this file we developed a program to either take the video input from the device or from youtube through url(we used pytube library),\n",
    "and the output of the program is also an video in which all the faces in each frame will be outlined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880adfe9",
   "metadata": {},
   "source": [
    "# Creating user defined function for the video to be processed when uploaded via youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b6c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating user defined functions for the video to be processed when uploaded via youtube\n",
    "def youtube_video(youtube_link):\n",
    "    y=YouTube(youtube_link) #uploading the video into the kernel\n",
    "    y_stream=y.streams.filter(only_video=True, file_extension='mp4').first() #yt is an instance of the YouTube class from the pytube library and here we filter only videos with mp4 extension\n",
    "    y_stream.download(filename='input_video') # here we download the video from the youtube \n",
    "    return 'output_video1.avi'\n",
    "\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3aeda8",
   "metadata": {},
   "source": [
    "# Creating user defined function for the video to be processed when uploaded via local device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc9c62",
   "metadata": {},
   "source": [
    "Here we use haarcascade  classifier to identify the faces, we used haar cascades because of their computational efficieny. In this classifier\n",
    "we use  simple rectangular patterns that spread all over the image or the frame and compare adjacent pixel values to identify the face.\n",
    "To increae the efficieny we use a function called integral image which allows for rapid calculation of the sum of pixel values in any rectangular region of the image.\n",
    "These Classifiers are trained using a large dataset of positive and negative images. where +ve images contain the object or feature of interest \n",
    "and -ve  images do not contain the object.\n",
    "Here the term cascade refers to a series of stages, where each stage contains multiple weak classifiers. so to boost the performance of weak \n",
    "classifiers we use ADA boost. Each classifier gives us a binary result(feature of interest or not) based on a threshold.\n",
    "The final decision is made by combining the results of all weak classifiers in a weighted manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73468f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_from_device(file_location):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    v=cv2.VideoCapture(file_location)\n",
    "    frame_number = 0\n",
    "    outlined=cv2.VideoWriter_fourcc(*'XVID')# used to specify the codec of compression \n",
    "    output_video=cv2.VideoWriter('output_video.avi', outlined, 30, (int(v.get(3)),int(v.get(4))))# Create a VideoWriter object to save the output video with face outlines\n",
    "    \n",
    "    while True:\n",
    "        ret,frame= v.read() #reading a frame from the video\n",
    "        if not ret: # if the frames are over then the while loop breakes\n",
    "            break\n",
    "            frame_number +=1\n",
    "        gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)# Convert the frame to grayscale for face detection\n",
    "        faces= face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(40,40))# Detect faces in the frame\n",
    "        for(a,b,c,d) in faces:\n",
    "            cv2.rectangle(frame, (a,b),(a+c,b+d),(0,0,255), 3)# Drawing red rectangles around the detected faces\n",
    "            output_video.write(frame)\n",
    "            cv2.imshow('Video', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    v.release()\n",
    "    output_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "                \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3eb5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option\n",
      "1. Process a video from YouTube\n",
      "2. Upload a video file\n",
      "Enter your choice (1 or 2) 2\n",
      "Enter the path of the video file: C:/Users/Shri/Pictures/Camera Roll/my_recording.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m     file_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter the path of the video file: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     output_video \u001b[38;5;241m=\u001b[39m video_from_device(file_location)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid choice. Please enter 1 or 2.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m, in \u001b[0;36mvideo_from_device\u001b[1;34m(file_location)\u001b[0m\n\u001b[0;32m     12\u001b[0m     frame_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     13\u001b[0m gray\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\u001b[38;5;66;03m# Convert the frame to grayscale for face detection\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m faces\u001b[38;5;241m=\u001b[39m face_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m40\u001b[39m))\u001b[38;5;66;03m# Detect faces in the frame\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m(a,b,c,d) \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[0;32m     16\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (a,b),(a\u001b[38;5;241m+\u001b[39mc,b\u001b[38;5;241m+\u001b[39md),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m3\u001b[39m)\u001b[38;5;66;03m# Drawing red rectangles around the detected faces\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Choose an option')\n",
    "    print('1. Process a video from YouTube')\n",
    "    print('2. Upload a video file')\n",
    "\n",
    "    choice = input('Enter your choice (1 or 2) ')\n",
    "\n",
    "    if choice == '1':\n",
    "        youtube_link = input('Enter the YouTube video URL: ')\n",
    "        output_video = youtube_video(youtube_link)\n",
    "    elif choice == '2':\n",
    "        file_location = input('Enter the path of the video file: ')\n",
    "        output_video = video_from_device(file_location)\n",
    "    else:\n",
    "        print('Invalid choice. Please enter 1 or 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2751afd",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a68a5",
   "metadata": {},
   "source": [
    "In conclusion after running the program on different video inputs we observed that if the face in the video is clear the classifer\n",
    "is clearly detecting the face and also the performance of the classifier depends on the amount of lighting upon the face.\n",
    "In simple terms the classifier is unable to detect the faces in background accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cffff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
